{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4147b09f",
   "metadata": {},
   "source": [
    "# Importing libraries and checking versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f71de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353983be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import vertical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b101371",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e6d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8af9e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:  3.9.7 (default, Sep 16 2021, 08:50:36) \n",
      "[Clang 10.0.0 ]\n",
      "Numpy:  1.21.5\n",
      "Matplotlib:  3.5.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Matplotlib: \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c2b88",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa99e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722fcc4",
   "metadata": {},
   "source": [
    "# Basic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a04eaa",
   "metadata": {},
   "source": [
    "## Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bfd99",
   "metadata": {},
   "source": [
    "### Input values\n",
    "the weight values will change as the neural network gets trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e5a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change as these are usually from your original data or outputs of other neurons \n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [5, 7, 3.4, -2],\n",
    "          [1, -2, 3, 6.5]]\n",
    "\n",
    "# usually change when training using back propagation\n",
    "weights0 = [[0.2, 0.9, 0.5, -0.3],\n",
    "           [-0.1, 0.8, -0.3, 0.6],\n",
    "           [0.3, -0.3, 0.6, -0.5]]\n",
    "\n",
    "weights1 = [[0.1, 0.4, -0.3],\n",
    "           [0.7, -0.4, 0.5],\n",
    "           [0.9, 0.4, 0.7]]\n",
    "\n",
    "# can change\n",
    "biases0 = [2, 4, 3]\n",
    "biases1 = [6, 2, -0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73324aaa",
   "metadata": {},
   "source": [
    "### Output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406d057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1_outputs = np.dot(inputs, np.array(weights0).T) + biases0\n",
    "# print(layer1_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd9f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer2_outputs = np.dot(layer1_outputs, np.array(weights1).T) + biases1\n",
    "# print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d6dd2",
   "metadata": {},
   "source": [
    "# Real Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b501fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input data\n",
    "# X = [[1, 2, 3, 2.5],\n",
    "#      [5, 7, 3.4, -2],\n",
    "#      [1, -2, 3, 6.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85533dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 3.3, 0, 2.2, 0]\n"
     ]
    }
   ],
   "source": [
    "# activation function\n",
    "inputs = [0, 2, -1, 3.3, -2.7, 2.2, -100]\n",
    "output = []\n",
    "\n",
    "for i in inputs:\n",
    "    output.append(max(0, i))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1dcb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53ca9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU = Rectified Linear Unit\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa4ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346f023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7824dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "        \n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif  len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "            \n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52faac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first variable is the number of inputs, second can be whatever you want\n",
    "#layer_1 = Layer_Dense(2, 5)\n",
    "# layer_2 = Layer_Dense(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8803897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation1 = Activation_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db4d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_1.forward(X)\n",
    "#print(layer_1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670fa491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation1.forward(layer_1.output)\n",
    "#print(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f6a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_2.forward(layer_1.output)\n",
    "# print(layer_2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f689a",
   "metadata": {},
   "source": [
    "# Soft max Activation Function\n",
    "used for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b39d3b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7605d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Layer_Dense(2,3)\n",
    "activation1 = Activation_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2e26119",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = Layer_Dense(3,3)\n",
    "activation2 = Activation_Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a87b204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b90cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e30fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333376 0.33333224 0.333334  ]\n",
      " [0.33334652 0.33330023 0.33335322]\n",
      " [0.33333334 0.33333334 0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccdcf11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.0985749\n"
     ]
    }
   ],
   "source": [
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "print('Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22e6c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [[4.8, 1.21, 2.385],\n",
    "                 [8.9, -1.81, 0.2],\n",
    "                 [1.41, 1.051, 0.026]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac5ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E = math.e\n",
    "exp_values = np.exp(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d8ee1",
   "metadata": {},
   "source": [
    "default axis is 'None' and all {9} numbers of layer outputs would be added together\n",
    "if its set to 0, the columns will be added\n",
    "if its set to 1, rows are added\n",
    "\n",
    "keepdims keeps the matrix in the same shape -> the rows are added across here, so it keeps them in a column\n",
    "'keep dimensions True' aka the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00d0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_values = exp_values / np.sum(exp_values, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e51a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
      " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
      " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(norm_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a509c",
   "metadata": {},
   "source": [
    "# Calculating Loss with Categorical Cross-Entropy\n",
    "one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27d509",
   "metadata": {},
   "source": [
    "solving for x in:\n",
    "e^x = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eb38ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66533923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6486586255873816\n",
      "5.199999999999999 which is approximately equal to  5.2\n"
     ]
    }
   ],
   "source": [
    "x = np.log(b)\n",
    "\n",
    "print(x)\n",
    "print((math.e ** x), 'which is approximately equal to ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc7d9d",
   "metadata": {},
   "source": [
    "### Actually calculating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad4afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = [0.7, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9a5bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_output = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7e30daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "# use math.log instead of np.log as numpy is not raw python\n",
    "loss = -(math.log(softmax_output[0])*target_output[0] + \n",
    "         math.log(softmax_output[1])*target_output[1] +\n",
    "         math.log(softmax_output[2])*target_output[2])\n",
    "print(loss)\n",
    "\n",
    "# same as saying -math.log(softmax_output[0]) as target_output 1 and 2 = 0\n",
    "\n",
    "print(-math.log(0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883aa75",
   "metadata": {},
   "source": [
    "# Implementing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f08b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "                            [0.1, 0.5, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c3a41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_targets = [0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2da90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_loss = -np.log(softmax_outputs[\n",
    "               range(len(softmax_outputs)), class_targets\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f87bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38506088005216804\n"
     ]
    }
   ],
   "source": [
    "average_loss = np.mean(neg_loss)\n",
    "print(average_loss)\n",
    "\n",
    "# can run into problems with 0 as log0 = infinity and this causes issues with finding the average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd27cc",
   "metadata": {},
   "source": [
    "# Optimization and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bb20e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = vertical_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f2279d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8117ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdac5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca0d0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = Loss_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebaa2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_loss = 9999999\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52249f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration:  0 loss:  1.0985026 acc: 0.3333333333333333\n",
      "New set of weights found, iteration:  1 loss:  1.0980016 acc: 0.3333333333333333\n",
      "New set of weights found, iteration:  2 loss:  1.0977929 acc: 0.3333333333333333\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (3,3) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m dense1\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m dense1\u001b[38;5;241m.\u001b[39mbiases \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m dense2\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      6\u001b[0m dense2\u001b[38;5;241m.\u001b[39mbiases \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m dense1\u001b[38;5;241m.\u001b[39mforward(X)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (3,3) (2,3) "
     ]
    }
   ],
   "source": [
    "for iteration in range(100000):\n",
    "    \n",
    "    dense1.weights += 0.05 * np.random.randn(2, 3)\n",
    "    dense1.biases += 0.05 * np.random.randn(1, 3)\n",
    "    dense2.weights += 0.05 * np.random.randn(3, 3)\n",
    "    dense2.biases += 0.05 * np.random.randn(1, 3)\n",
    "    \n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "    \n",
    "    loss = loss_function.calculate(activation2.output, y)\n",
    "    \n",
    "    predictions = np.argmax(activation2.output, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if loss < lowest_loss:\n",
    "        print('New set of weights found, iteration: ', iteration,\n",
    "             'loss: ', loss, 'acc:', accuracy)\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense1.weights.copy()\n",
    "        best_dense2_biases = dense1.biases.copy()\n",
    "        lowest_loss = loss\n",
    "        \n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
